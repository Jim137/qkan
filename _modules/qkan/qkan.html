

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>qkan.qkan &mdash; QKAN 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=e59714d7" />

  
      <script src="../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../_static/documentation_options.js?v=01f34227"></script>
      <script src="../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            QKAN
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples.html">Examples &amp; Applications</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">QKAN</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">qkan.qkan</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for qkan.qkan</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Quantum-inspired Kolmogorov Arnold Networks (QKANs) implementation in PyTorch.</span>
<span class="sd">Paper: Quantum Variational Activation Functions Empower Kolmogorov-Arnold Networks: https://arxiv.org/abs/2509.14026</span>

<span class="sd">Supported solvers:</span>
<span class="sd">    - PennyLane</span>
<span class="sd">    - Exact solver implemented in PyTorch (faster)</span>
<span class="sd">    - Custom solvers api</span>

<span class="sd">Code author: Jiun-Cheng Jiang (Jim137@GitHub)</span>
<span class="sd">Contact: [jcjiang@phys.ntu.edu.tw](mailto:jcjiang@phys.ntu.edu.tw)</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">copy</span><span class="w"> </span><span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">glob</span><span class="w"> </span><span class="kn">import</span> <span class="n">glob</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Literal</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>  <span class="c1"># type: ignore</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>  <span class="c1"># type: ignore</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">.solver</span><span class="w"> </span><span class="kn">import</span> <span class="n">qml_solver</span><span class="p">,</span> <span class="n">torch_exact_solver</span>


<div class="viewcode-block" id="QKANLayer">
<a class="viewcode-back" href="../../api.html#qkan.QKANLayer">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">QKANLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    QKANLayer Class</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">        in_dim : int</span>
<span class="sd">            Input dimension</span>
<span class="sd">        out_dim : int</span>
<span class="sd">            Output dimension</span>
<span class="sd">        reps : int</span>
<span class="sd">            Repetitions of quantum layers</span>
<span class="sd">        group : int</span>
<span class="sd">            Group of neurons</span>
<span class="sd">        device :</span>
<span class="sd">            Device to use</span>
<span class="sd">        solver : Union[Literal[&quot;qml&quot;, &quot;exact&quot;], Callable]</span>
<span class="sd">            Solver to use</span>
<span class="sd">        ansatz : Union[str, Callable]</span>
<span class="sd">            Ansatz to use, &quot;pz_encoding&quot;, &quot;px_encoding&quot;, &quot;rpz_encoding&quot; or custom</span>
<span class="sd">        qml_device : str</span>
<span class="sd">            PennyLane device to use</span>
<span class="sd">        theta : nn.Parameter</span>
<span class="sd">            Learnable parameter of quantum circuit</span>
<span class="sd">        base_weight : nn.Parameter</span>
<span class="sd">            Learnable parameter of base activation</span>
<span class="sd">        preact_trainable : bool</span>
<span class="sd">            Whether preact weights are trainable</span>
<span class="sd">        preacts_weight : nn.Parameter</span>
<span class="sd">            Learnable parameter of preact weights</span>
<span class="sd">        preacts_bias : nn.Parameter</span>
<span class="sd">            Learnable parameter of preact bias</span>
<span class="sd">        postact_weight_trainable : bool</span>
<span class="sd">            Whether postact weights are trainable</span>
<span class="sd">        postact_weights : nn.Parameter</span>
<span class="sd">            Learnable parameter of postact weights</span>
<span class="sd">        postact_bias_trainable : bool</span>
<span class="sd">            Whether postact bias are trainable</span>
<span class="sd">        postact_bias : nn.Parameter</span>
<span class="sd">            Learnable parameter of postact bias</span>
<span class="sd">        mask : nn.Parameter</span>
<span class="sd">            Mask for pruning</span>
<span class="sd">        is_batchnorm : bool</span>
<span class="sd">            Whether to use batch normalization</span>
<span class="sd">        _x0 : Optional[torch.Tensor]</span>
<span class="sd">            Leave for ResQKANLayer</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">out_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">reps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">group</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
        <span class="n">solver</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;qml&quot;</span><span class="p">,</span> <span class="s2">&quot;exact&quot;</span><span class="p">],</span> <span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;exact&quot;</span><span class="p">,</span>
        <span class="n">qml_device</span><span class="o">=</span><span class="s2">&quot;default.qubit&quot;</span><span class="p">,</span>
        <span class="n">ansatz</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;pz_encoding&quot;</span><span class="p">,</span>
        <span class="n">theta_size</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">preact_trainable</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">preact_init</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">postact_weight_trainable</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">postact_bias_trainable</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">base_activation</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">SiLU</span><span class="p">(),</span>
        <span class="n">ba_trainable</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">is_batchnorm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">QKANLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">group</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">group</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                <span class="n">group</span> <span class="o">=</span> <span class="p">(</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">in_dim</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">group</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="n">group</span><span class="p">])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">in_dim</span> <span class="o">=</span> <span class="n">in_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_dim</span> <span class="o">=</span> <span class="n">out_dim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reps</span> <span class="o">=</span> <span class="n">reps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">group</span> <span class="o">=</span> <span class="n">group</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;qml&quot;</span><span class="p">,</span> <span class="s2">&quot;exact&quot;</span><span class="p">],</span> <span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="n">solver</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qml_device</span> <span class="o">=</span> <span class="n">qml_device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ansatz</span> <span class="o">=</span> <span class="n">ansatz</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">theta_size</span> <span class="o">=</span> <span class="n">theta_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_activation</span> <span class="o">=</span> <span class="n">base_activation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ba_trainable</span> <span class="o">=</span> <span class="n">ba_trainable</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_batchnorm</span> <span class="o">=</span> <span class="n">is_batchnorm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>

        <span class="k">if</span> <span class="nb">callable</span><span class="p">(</span><span class="s2">&quot;solver&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">callable</span><span class="p">(</span><span class="s2">&quot;ansatz&quot;</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">theta_size</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;theta_size is required for custom ansatz&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_normal_</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="o">*</span><span class="n">theta_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">ansatz</span> <span class="o">==</span> <span class="s2">&quot;pz_encoding&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_normal_</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="o">*</span><span class="n">group</span><span class="p">,</span> <span class="n">reps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">ansatz</span> <span class="o">==</span> <span class="s2">&quot;rpz_encoding&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">preact_trainable</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s2">&quot;Reduced pz encoding requires preact_trainable=True, set automatically.&quot;</span>
                <span class="p">)</span>
                <span class="n">preact_trainable</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_normal_</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="o">*</span><span class="n">group</span><span class="p">,</span> <span class="n">reps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">ansatz</span> <span class="o">==</span> <span class="s2">&quot;px_encoding&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">theta</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_normal_</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="o">*</span><span class="n">group</span><span class="p">,</span> <span class="n">reps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">ba_trainable</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">base_weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
                <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
                <span class="n">requires_grad</span><span class="o">=</span><span class="n">ba_trainable</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">base_weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="n">ba_trainable</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">preact_trainable</span> <span class="o">=</span> <span class="n">preact_trainable</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">preact_init</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">preacts_weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="o">*</span><span class="n">group</span><span class="p">,</span> <span class="n">reps</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
                <span class="n">requires_grad</span><span class="o">=</span><span class="n">preact_trainable</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">preacts_bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="o">*</span><span class="n">group</span><span class="p">,</span> <span class="n">reps</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
                <span class="n">requires_grad</span><span class="o">=</span><span class="n">preact_trainable</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">preacts_weight</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_normal_</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="o">*</span><span class="n">group</span><span class="p">,</span> <span class="n">reps</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)),</span>
                <span class="n">requires_grad</span><span class="o">=</span><span class="n">preact_trainable</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">preacts_bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_normal_</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="o">*</span><span class="n">group</span><span class="p">,</span> <span class="n">reps</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)),</span>
                <span class="n">requires_grad</span><span class="o">=</span><span class="n">preact_trainable</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">preact_init</span> <span class="o">=</span> <span class="n">preact_init</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">postact_weight_trainable</span> <span class="o">=</span> <span class="n">postact_weight_trainable</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">postact_weights</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
            <span class="n">requires_grad</span><span class="o">=</span><span class="n">postact_weight_trainable</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">postact_bias_trainable</span> <span class="o">=</span> <span class="n">postact_bias_trainable</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">postact_bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
            <span class="n">requires_grad</span><span class="o">=</span><span class="n">postact_bias_trainable</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">is_batchnorm</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">bn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_x0</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

<div class="viewcode-block" id="QKANLayer.to">
<a class="viewcode-back" href="../../api.html#qkan.QKANLayer.to">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Move the layer to the specified device.</span>

<span class="sd">        Args</span>
<span class="sd">        ----</span>
<span class="sd">            device : str | torch.device</span>
<span class="sd">                Device to move the layer to, default: &quot;cpu&quot;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">QKANLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span></div>


    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">param_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_param_size&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_param_size</span>
        <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
                <span class="n">count</span> <span class="o">+=</span> <span class="n">param</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_param_size</span> <span class="o">=</span> <span class="n">count</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_param_size</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">x0</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_x0</span>

    <span class="nd">@x0</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">x0</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_x0</span> <span class="o">=</span> <span class="kc">None</span>

<div class="viewcode-block" id="QKANLayer.forward">
<a class="viewcode-back" href="../../api.html#qkan.QKANLayer.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="s2">&quot;Invalid input dimension&quot;</span>

        <span class="n">batch</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_batchnorm</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">base_output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
            <span class="s2">&quot;oi,bi-&gt;boi&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_activation</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span> <span class="o">==</span> <span class="s2">&quot;qml&quot;</span><span class="p">:</span>
            <span class="n">postacts</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_dim</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_dim</span><span class="p">):</span>
                    <span class="n">postacts</span><span class="p">[:,</span> <span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">qml_solver</span><span class="p">(</span>
                        <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span>
                        <span class="n">theta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span>
                        <span class="n">reps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reps</span><span class="p">,</span>
                        <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                        <span class="n">qml_device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">qml_device</span><span class="p">,</span>
                    <span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span> <span class="o">==</span> <span class="s2">&quot;exact&quot;</span><span class="p">:</span>
            <span class="n">postacts</span> <span class="o">=</span> <span class="n">torch_exact_solver</span><span class="p">(</span>
                <span class="n">x</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">preacts_weight</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">preacts_bias</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reps</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="n">ansatz</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ansatz</span><span class="p">,</span>
                <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">group</span><span class="p">,</span>
                <span class="n">preacts_trainable</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">preact_trainable</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">callable</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="p">):</span>
            <span class="n">postacts</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="p">(</span>
                <span class="n">x</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">preacts_weight</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">preacts_bias</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reps</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="n">ansatz</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ansatz</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">postacts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_dim</span><span class="p">:</span>
            <span class="n">postacts</span> <span class="o">=</span> <span class="n">postacts</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
            <span class="p">(</span>
                <span class="p">(</span><span class="n">postacts</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">postact_bias</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">postact_weights</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
                <span class="o">+</span> <span class="n">base_output</span>
            <span class="p">)</span>
            <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:],</span>
            <span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span></div>


<div class="viewcode-block" id="QKANLayer.reset_parameters">
<a class="viewcode-back" href="../../api.html#qkan.QKANLayer.reset_parameters">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">reset_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span></div>


<div class="viewcode-block" id="QKANLayer.forward_no_sum">
<a class="viewcode-back" href="../../api.html#qkan.QKANLayer.forward_no_sum">[docs]</a>
    <span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward_no_sum</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_dim</span><span class="p">,</span> <span class="s2">&quot;Invalid input dimension&quot;</span>

        <span class="n">base_output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
            <span class="s2">&quot;oi,bi-&gt;boi&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_activation</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span> <span class="o">==</span> <span class="s2">&quot;qml&quot;</span><span class="p">:</span>
            <span class="n">postacts</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                        <span class="p">[</span>
                            <span class="n">qml_solver</span><span class="p">(</span>
                                <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">[:,</span> <span class="n">i</span><span class="p">],</span>
                                <span class="n">theta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span>
                                <span class="n">reps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reps</span><span class="p">,</span>
                                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                                <span class="n">qml_device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">qml_device</span><span class="p">,</span>
                            <span class="p">)</span>
                            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span>
                        <span class="p">],</span>
                    <span class="p">)</span>
                    <span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                    <span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_dim</span><span class="p">)</span>
                <span class="p">],</span>
                <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">solver</span> <span class="o">==</span> <span class="s2">&quot;exact&quot;</span><span class="p">:</span>
            <span class="n">postacts</span> <span class="o">=</span> <span class="n">torch_exact_solver</span><span class="p">(</span>
                <span class="n">x</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">preacts_weight</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">preacts_bias</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">reps</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                <span class="n">ansatz</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ansatz</span><span class="p">,</span>
                <span class="n">group</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">group</span><span class="p">,</span>
                <span class="n">preacts_trainable</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">preact_trainable</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
        <span class="n">x_new</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">postacts</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">postact_bias</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">postact_weights</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
            <span class="o">+</span> <span class="n">base_output</span>
        <span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
        <span class="k">return</span> <span class="n">x_new</span></div>


<div class="viewcode-block" id="QKANLayer.get_subset">
<a class="viewcode-back" href="../../api.html#qkan.QKANLayer.get_subset">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_subset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_id</span><span class="p">,</span> <span class="n">out_id</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get a smaller QKANLayer from a larger QKANLayer (used for pruning).</span>

<span class="sd">        Args</span>
<span class="sd">        ----</span>
<span class="sd">            in_id : list</span>
<span class="sd">                id of selected input neurons</span>
<span class="sd">            out_id : list</span>
<span class="sd">                id of selected output neurons</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">            QKANLayer</span>
<span class="sd">                New QKANLayer with selected neurons</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">spb</span> <span class="o">=</span> <span class="n">QKANLayer</span><span class="p">(</span>
            <span class="n">in_dim</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">in_id</span><span class="p">),</span>
            <span class="n">out_dim</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">out_id</span><span class="p">),</span>
            <span class="n">reps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reps</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="n">solver</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="p">,</span>
            <span class="n">qml_device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">qml_device</span><span class="p">,</span>
            <span class="n">ansatz</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ansatz</span><span class="p">,</span>
            <span class="n">preact_trainable</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">preact_trainable</span><span class="p">,</span>
            <span class="n">postact_weight_trainable</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">postact_weight_trainable</span><span class="p">,</span>
            <span class="n">postact_bias_trainable</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">postact_bias_trainable</span><span class="p">,</span>
            <span class="n">base_activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">base_activation</span><span class="p">,</span>
            <span class="n">ba_trainable</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ba_trainable</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">spb</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">theta</span><span class="p">[</span><span class="n">out_id</span><span class="p">][:,</span> <span class="n">in_id</span><span class="p">]</span>
        <span class="n">spb</span><span class="o">.</span><span class="n">base_weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_weight</span><span class="p">[</span><span class="n">out_id</span><span class="p">][:,</span> <span class="n">in_id</span><span class="p">]</span>
        <span class="n">spb</span><span class="o">.</span><span class="n">preacts_weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preacts_weight</span><span class="p">[</span><span class="n">out_id</span><span class="p">][:,</span> <span class="n">in_id</span><span class="p">]</span>
        <span class="n">spb</span><span class="o">.</span><span class="n">preacts_bias</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preacts_bias</span><span class="p">[</span><span class="n">out_id</span><span class="p">][:,</span> <span class="n">in_id</span><span class="p">]</span>
        <span class="n">spb</span><span class="o">.</span><span class="n">postact_weights</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">postact_weights</span><span class="p">[</span><span class="n">out_id</span><span class="p">][:,</span> <span class="n">in_id</span><span class="p">]</span>
        <span class="n">spb</span><span class="o">.</span><span class="n">postact_bias</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">postact_bias</span><span class="p">[</span><span class="n">out_id</span><span class="p">][:,</span> <span class="n">in_id</span><span class="p">]</span>
        <span class="n">spb</span><span class="o">.</span><span class="n">mask</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">[</span><span class="n">out_id</span><span class="p">][:,</span> <span class="n">in_id</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">spb</span></div>
</div>



<span class="k">class</span><span class="w"> </span><span class="nc">QKANModuleList</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">QKANModuleList</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="c1"># make type hint for getitem method</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">QKANLayer</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">,</span> <span class="s2">&quot;QKANModuleList&quot;</span><span class="p">]:</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">(</span><span class="n">QKANModuleList</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__getitem__</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>


<div class="viewcode-block" id="QKAN">
<a class="viewcode-back" href="../../api.html#qkan.QKAN">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">QKAN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Quantum-inspired Kolmogorov Arnold Network (QKAN) Class</span>

<span class="sd">    A quantum-inspired neural network that uses DatA Re-Uploading ActivatioN (DARUAN)</span>
<span class="sd">    as its learnable variation activation function.</span>

<span class="sd">    References:</span>
<span class="sd">        Quantum Variational Activation Functions Empower Kolmogorov-Arnold Networks: https://arxiv.org/abs/2509.14026</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">        width : list[int]</span>
<span class="sd">            List of width of each layer</span>
<span class="sd">        reps : int</span>
<span class="sd">            Repetitions of quantum layers</span>
<span class="sd">        group : int</span>
<span class="sd">            Group of neurons</span>
<span class="sd">        device : Literal[&quot;cpu&quot;, &quot;cuda&quot;]</span>
<span class="sd">            Device to use</span>
<span class="sd">        solver : Literal[&quot;qml&quot;, &quot;exact&quot;]</span>
<span class="sd">            Solver to use</span>
<span class="sd">        qml_device : str</span>
<span class="sd">            PennyLane device to use</span>
<span class="sd">        layers : QKANModuleList</span>
<span class="sd">            List of layers</span>
<span class="sd">        is_map : bool</span>
<span class="sd">            Whether to use map layer</span>
<span class="sd">        is_batchnorm : bool</span>
<span class="sd">            Whether to use batch normalization</span>
<span class="sd">        reps : int</span>
<span class="sd">            Repetitions of quantum layers</span>
<span class="sd">        norm_out : int</span>
<span class="sd">            Normalize output</span>
<span class="sd">        postact_weight_trainable : bool</span>
<span class="sd">            Whether postact weights are trainable</span>
<span class="sd">        postact_bias_trainable : bool</span>
<span class="sd">            Whether postact bias are trainable</span>
<span class="sd">        preact_trainable : bool</span>
<span class="sd">            Whether preact weights are trainable</span>
<span class="sd">        base_activation : torch.nn.Module or lambda function</span>
<span class="sd">            Base activation function</span>
<span class="sd">        ba_trainable : bool</span>
<span class="sd">            Whether base activation weights are trainable</span>
<span class="sd">        save_act : bool</span>
<span class="sd">            Whether to save activations</span>
<span class="sd">        seed : int</span>
<span class="sd">            Random seed</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">width</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
        <span class="n">reps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">group</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">is_map</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">is_batchnorm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">hidden</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
        <span class="n">solver</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;qml&quot;</span><span class="p">,</span> <span class="s2">&quot;exact&quot;</span><span class="p">],</span> <span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;exact&quot;</span><span class="p">,</span>
        <span class="n">qml_device</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;default.qubit&quot;</span><span class="p">,</span>
        <span class="n">ansatz</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;pz_encoding&quot;</span><span class="p">,</span>
        <span class="n">norm_out</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">preact_trainable</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">preact_init</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">postact_weight_trainable</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">postact_bias_trainable</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">base_activation</span><span class="o">=</span><span class="n">nn</span><span class="o">.</span><span class="n">SiLU</span><span class="p">(),</span>
        <span class="n">ba_trainable</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">save_act</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize QKAN model</span>

<span class="sd">        Args</span>
<span class="sd">        ----</span>
<span class="sd">            width : list[int]</span>
<span class="sd">                List of width of each layer</span>
<span class="sd">            reps : int</span>
<span class="sd">                Repetitions of quantum layers, default: 3</span>
<span class="sd">            group : int</span>
<span class="sd">                Group of neurons, default: -1</span>
<span class="sd">            is_map : bool</span>
<span class="sd">                Whether to use map layer, default: False</span>
<span class="sd">            is_batchnorm: bool</span>
<span class="sd">                Whether to add a batchnorm layer before QKANLayer, default: False</span>
<span class="sd">            hidden : int</span>
<span class="sd">                Number of hidden units in map layer, default: 0</span>
<span class="sd">            device :</span>
<span class="sd">                Device to use, default: &quot;cpu&quot;</span>
<span class="sd">            solver : Union[Literal[&quot;qml&quot;, &quot;exact&quot;], Callable]</span>
<span class="sd">                Solver to use, default: &quot;exact&quot;</span>
<span class="sd">            ansatz : Union[str, Callable]</span>
<span class="sd">                Ansatz to use, &quot;pz_encoding&quot;, &quot;px_encoding&quot;, &quot;rpz_encoding&quot; or custom</span>
<span class="sd">            qml_device : str</span>
<span class="sd">                PennyLane device to use, default: &quot;default.qubit&quot;</span>
<span class="sd">            ansatz : str | Callable</span>
<span class="sd">                Ansatz to use, default: &quot;pz_encoding&quot;</span>
<span class="sd">            norm_out : int</span>
<span class="sd">                Normalize output, default: 0</span>
<span class="sd">            postact_weight_trainable : bool</span>
<span class="sd">                Whether postact weights are trainable, default: False</span>
<span class="sd">            postact_bias_trainable : bool</span>
<span class="sd">                Whether postact bias are trainable, default: False</span>
<span class="sd">            base_activation : torch.nn.Module | lambda function</span>
<span class="sd">                Base activation function, default: torch.nn.SiLU()</span>
<span class="sd">            ba_trainable : bool</span>
<span class="sd">                Whether base activation weights are trainable, default: False</span>
<span class="sd">            save_act : bool</span>
<span class="sd">                Whether to save activations, default: False</span>
<span class="sd">            seed : int</span>
<span class="sd">                Random seed, default: 0</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">QKAN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">depth</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">width</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="mi">2</span> <span class="k">if</span> <span class="n">is_map</span> <span class="k">else</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">width</span> <span class="o">=</span> <span class="n">width</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reps</span> <span class="o">=</span> <span class="n">reps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">group</span> <span class="o">=</span> <span class="n">group</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;qml&quot;</span><span class="p">,</span> <span class="s2">&quot;exact&quot;</span><span class="p">],</span> <span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="n">solver</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ansatz</span> <span class="o">=</span> <span class="n">ansatz</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">qml_device</span> <span class="o">=</span> <span class="n">qml_device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">norm_out</span> <span class="o">=</span> <span class="n">norm_out</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">postact_weight_trainable</span> <span class="o">=</span> <span class="n">postact_weight_trainable</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">postact_bias_trainable</span> <span class="o">=</span> <span class="n">postact_bias_trainable</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">preact_trainable</span> <span class="o">=</span> <span class="n">preact_trainable</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">preact_init</span> <span class="o">=</span> <span class="n">preact_init</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">base_activation</span> <span class="o">=</span> <span class="n">base_activation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ba_trainable</span> <span class="o">=</span> <span class="n">ba_trainable</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_act</span> <span class="o">=</span> <span class="n">save_act</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">QKANModuleList</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">depth</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">QKANLayer</span><span class="p">(</span>
                    <span class="n">in_dim</span><span class="o">=</span><span class="n">width</span><span class="p">[</span><span class="n">l</span><span class="p">],</span>
                    <span class="n">out_dim</span><span class="o">=</span><span class="n">width</span><span class="p">[</span><span class="n">l</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span>
                    <span class="n">reps</span><span class="o">=</span><span class="n">reps</span><span class="p">,</span>
                    <span class="n">group</span><span class="o">=</span><span class="n">group</span><span class="p">,</span>
                    <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                    <span class="n">solver</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="p">,</span>
                    <span class="n">qml_device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">qml_device</span><span class="p">,</span>
                    <span class="n">ansatz</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ansatz</span><span class="p">,</span>
                    <span class="n">preact_trainable</span><span class="o">=</span><span class="n">preact_trainable</span><span class="p">,</span>
                    <span class="n">preact_init</span><span class="o">=</span><span class="n">preact_init</span><span class="p">,</span>
                    <span class="n">postact_weight_trainable</span><span class="o">=</span><span class="n">postact_weight_trainable</span><span class="p">,</span>
                    <span class="n">postact_bias_trainable</span><span class="o">=</span><span class="n">postact_bias_trainable</span><span class="p">,</span>
                    <span class="n">base_activation</span><span class="o">=</span><span class="n">base_activation</span><span class="p">,</span>
                    <span class="n">ba_trainable</span><span class="o">=</span><span class="n">ba_trainable</span><span class="p">,</span>
                    <span class="n">is_batchnorm</span><span class="o">=</span><span class="n">is_batchnorm</span><span class="p">,</span>
                    <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">is_batchnorm</span> <span class="o">=</span> <span class="n">is_batchnorm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_map</span> <span class="o">=</span> <span class="n">is_map</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden</span> <span class="o">=</span> <span class="n">hidden</span>
        <span class="k">if</span> <span class="n">is_map</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">width</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">hidden</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">SiLU</span><span class="p">())</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden</span><span class="p">,</span> <span class="n">width</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

<div class="viewcode-block" id="QKAN.to">
<a class="viewcode-back" href="../../api.html#qkan.QKAN.to">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Move the model to the specified device.</span>

<span class="sd">        Args</span>
<span class="sd">        ----</span>
<span class="sd">            device : str | torch.device</span>
<span class="sd">                Device to move the model to, default: &quot;cpu&quot;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">QKAN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="n">layer</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span></div>


    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">param_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;_param_size&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_param_size</span>
        <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">QKANLayer</span><span class="p">):</span>
                <span class="n">count</span> <span class="o">+=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">p</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
                <span class="k">continue</span>
            <span class="n">count</span> <span class="o">+=</span> <span class="n">layer</span><span class="o">.</span><span class="n">param_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_param_size</span> <span class="o">=</span> <span class="n">count</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_param_size</span>

<div class="viewcode-block" id="QKAN.forward">
<a class="viewcode-back" href="../../api.html#qkan.QKAN.forward">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="n">shape_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">shape_size</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">T</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">elif</span> <span class="n">shape_size</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">B</span><span class="p">,</span> <span class="n">T</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">T</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_id</span><span class="o">.</span><span class="n">long</span><span class="p">()]</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_act</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cache_data</span> <span class="o">=</span> <span class="n">x</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">acts</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># shape ([batch, n0], [batch, n1], ..., [batch, n_L])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">subnode_actscale</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dr_preacts</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dr_postacts</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">acts_scale</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">acts_scale_dr</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">edge_actscale</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">acts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">clone</span><span class="p">())</span>

        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_act</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">QKANLayer</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">subnode_actscale</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
                <span class="n">preacts</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">clone</span><span class="p">())[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span>
                <span class="n">postacts</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">forward_no_sum</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># shape: (batch, out_dim, in_dim)</span>

            <span class="n">x</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_act</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">QKANLayer</span><span class="p">):</span>
                <span class="n">input_range</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">preacts</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.1</span>
                <span class="n">output_range_dr</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span>
                    <span class="n">postacts</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span>
                <span class="p">)</span>  <span class="c1"># for training, only penalize the dr part</span>
                <span class="n">output_range</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">std</span><span class="p">(</span>
                    <span class="n">postacts</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span>
                <span class="p">)</span>  <span class="c1"># leave for symbolic (Not implemented yet)</span>
                <span class="c1"># save edge_scale</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">edge_actscale</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_range</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">acts_scale</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">output_range</span> <span class="o">/</span> <span class="n">input_range</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">acts_scale_dr</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_range_dr</span> <span class="o">/</span> <span class="n">input_range</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">dr_preacts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">preacts</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">dr_postacts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">postacts</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">acts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">detach</span><span class="p">())</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">norm_out</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">norm_out</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">U</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">shape_size</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">U</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">shape_size</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">U</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span></div>


<div class="viewcode-block" id="QKAN.initialize_from_another_model">
<a class="viewcode-back" href="../../api.html#qkan.QKAN.initialize_from_another_model">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">initialize_from_another_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">another_model</span><span class="p">:</span> <span class="s2">&quot;QKAN&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize from another model.</span>
<span class="sd">        Used for layer extension to refine the model.</span>

<span class="sd">        Args</span>
<span class="sd">        ----</span>
<span class="sd">            another_model : QKAN</span>
<span class="sd">                Another model to initialize from</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="n">x</span> <span class="o">==</span> <span class="n">y</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="p">,</span> <span class="n">another_model</span><span class="o">.</span><span class="n">width</span><span class="p">)),</span> <span class="p">(</span>
            <span class="s2">&quot;Cannot initialize from another model with different width&quot;</span>
        <span class="p">)</span>
        <span class="n">count</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span>
        <span class="k">for</span> <span class="n">l</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">QKANLayer</span><span class="p">):</span>
                <span class="n">layer</span><span class="o">.</span><span class="n">reset_parameters</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">another_model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">reps</span><span class="p">):</span>
                    <span class="n">layer</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">data</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span>
                        <span class="n">another_model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">data</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">,</span> <span class="p">:]</span>
                    <span class="p">)</span>
                    <span class="n">layer</span><span class="o">.</span><span class="n">preacts_weight</span><span class="o">.</span><span class="n">data</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span>
                        <span class="n">another_model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">preacts_weight</span><span class="o">.</span><span class="n">data</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">]</span>
                    <span class="p">)</span>
                    <span class="n">layer</span><span class="o">.</span><span class="n">preacts_bias</span><span class="o">.</span><span class="n">data</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span>
                        <span class="n">another_model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">preacts_bias</span><span class="o">.</span><span class="n">data</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">]</span>
                    <span class="p">)</span>
                <span class="n">layer</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">data</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">another_model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">reps</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span>
                    <span class="n">another_model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">theta</span><span class="o">.</span><span class="n">data</span><span class="p">[</span>
                        <span class="p">:,</span> <span class="p">:,</span> <span class="n">another_model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">reps</span><span class="p">,</span> <span class="p">:</span>
                    <span class="p">]</span>
                <span class="p">)</span>
                <span class="n">layer</span><span class="o">.</span><span class="n">postact_weights</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span>
                    <span class="n">another_model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">postact_weights</span><span class="o">.</span><span class="n">data</span>
                <span class="p">)</span>
                <span class="n">layer</span><span class="o">.</span><span class="n">postact_bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">another_model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">postact_bias</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
                <span class="n">layer</span><span class="o">.</span><span class="n">base_weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">another_model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">l</span><span class="p">]</span><span class="o">.</span><span class="n">base_weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
                <span class="n">layer</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">another_model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">count</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
                <span class="n">layer</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">another_model</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">count</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
                <span class="n">count</span> <span class="o">+=</span> <span class="mi">2</span>
        <span class="k">return</span> <span class="bp">self</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_reg</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">reg_metric</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">lamb_l1</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">lamb_entropy</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">lamb_coef</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">lamb_coefdiff</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get regularization.</span>

<span class="sd">        Adapted from &quot;pykan&quot;.</span>

<span class="sd">        Args</span>
<span class="sd">        ----</span>
<span class="sd">            reg_metric : the regularization metric</span>
<span class="sd">                &#39;edge_forward_dr_n&#39;, &#39;edge_forward_dr_u&#39;, &#39;edge_forward_sum&#39;, &#39;edge_backward&#39;, &#39;node_backward&#39;</span>
<span class="sd">            lamb_l1 : float</span>
<span class="sd">                l1 penalty strength</span>
<span class="sd">            lamb_entropy : float</span>
<span class="sd">                entropy penalty strength</span>
<span class="sd">            lamb_coef : float</span>
<span class="sd">                coefficient penalty strength</span>
<span class="sd">            lamb_coefdiff : float</span>
<span class="sd">                coefficient smoothness strength</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">            torch.Tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">reg_metric</span> <span class="o">==</span> <span class="s2">&quot;edge_forward_dr_n&quot;</span><span class="p">:</span>
            <span class="n">acts_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">acts_scale_dr</span>
        <span class="k">elif</span> <span class="n">reg_metric</span> <span class="o">==</span> <span class="s2">&quot;edge_forward_sum&quot;</span><span class="p">:</span>
            <span class="n">acts_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">acts_scale</span>
        <span class="k">elif</span> <span class="n">reg_metric</span> <span class="o">==</span> <span class="s2">&quot;edge_forward_dr_u&quot;</span><span class="p">:</span>
            <span class="n">acts_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_actscale</span>
        <span class="k">elif</span> <span class="n">reg_metric</span> <span class="o">==</span> <span class="s2">&quot;edge_backward&quot;</span><span class="p">:</span>
            <span class="n">acts_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_scores</span>
        <span class="k">elif</span> <span class="n">reg_metric</span> <span class="o">==</span> <span class="s2">&quot;node_backward&quot;</span><span class="p">:</span>
            <span class="n">acts_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_attribute_scores</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;reg_metric = </span><span class="si">{</span><span class="n">reg_metric</span><span class="si">}</span><span class="s2"> not recognized!&quot;</span><span class="p">)</span>

        <span class="n">reg_</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">acts_scale</span><span class="p">)):</span>
            <span class="n">vec</span> <span class="o">=</span> <span class="n">acts_scale</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

            <span class="n">l1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">vec</span><span class="p">)</span>
            <span class="n">p_row</span> <span class="o">=</span> <span class="n">vec</span> <span class="o">/</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">vec</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">p_col</span> <span class="o">=</span> <span class="n">vec</span> <span class="o">/</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">vec</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">entropy_row</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">p_row</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">p_row</span> <span class="o">+</span> <span class="mf">1e-4</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">entropy_col</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">p_col</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">p_col</span> <span class="o">+</span> <span class="mf">1e-4</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">reg_</span> <span class="o">+=</span> <span class="n">lamb_l1</span> <span class="o">*</span> <span class="n">l1</span> <span class="o">+</span> <span class="n">lamb_entropy</span> <span class="o">*</span> <span class="p">(</span>
                <span class="n">entropy_row</span> <span class="o">+</span> <span class="n">entropy_col</span>
            <span class="p">)</span>  <span class="c1"># both l1 and entropy</span>

        <span class="c1"># regularize coefficient to encourage activation to be zero</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">QKANLayer</span><span class="p">):</span>
                <span class="k">continue</span>
            <span class="n">coeff_l1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">postact_weights</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">coeff_diff_l1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">postact_weights</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">reg_</span> <span class="o">+=</span> <span class="n">lamb_coef</span> <span class="o">*</span> <span class="n">coeff_l1</span> <span class="o">+</span> <span class="n">lamb_coefdiff</span> <span class="o">*</span> <span class="n">coeff_diff_l1</span>

        <span class="k">return</span> <span class="n">reg_</span>

<div class="viewcode-block" id="QKAN.get_reg">
<a class="viewcode-back" href="../../api.html#qkan.QKAN.get_reg">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">get_reg</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">reg_metric</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">lamb_l1</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">lamb_entropy</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">lamb_coef</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">lamb_coefdiff</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get regularization from the model.</span>

<span class="sd">        Adapted from &quot;pykan&quot;.</span>

<span class="sd">        Args</span>
<span class="sd">        ----</span>
<span class="sd">            reg_metric : str</span>
<span class="sd">                Regularization metric.</span>
<span class="sd">                &#39;edge_forward_dr_n&#39;, &#39;edge_forward_dr_u&#39;, &#39;edge_forward_sum&#39;, &#39;edge_backward&#39;, &#39;node_backward&#39;</span>
<span class="sd">            lamb_l1 : float</span>
<span class="sd">                L1 Regularization parameter</span>
<span class="sd">            lamb_entropy : float</span>
<span class="sd">                Entropy Regularization parameter</span>
<span class="sd">            lamb_coef : float</span>
<span class="sd">                Coefficient Regularization parameter</span>
<span class="sd">            lamb_coefdiff : float</span>
<span class="sd">                Coefficient Smoothness Regularization parameter</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">            torch.Tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_reg</span><span class="p">(</span><span class="n">reg_metric</span><span class="p">,</span> <span class="n">lamb_l1</span><span class="p">,</span> <span class="n">lamb_entropy</span><span class="p">,</span> <span class="n">lamb_coef</span><span class="p">,</span> <span class="n">lamb_coefdiff</span><span class="p">)</span></div>


<div class="viewcode-block" id="QKAN.attribute">
<a class="viewcode-back" href="../../api.html#qkan.QKAN.attribute">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">attribute</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">l</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">i</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">out_score</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get attribution scores</span>

<span class="sd">        Adapted from &quot;pykan&quot;.</span>

<span class="sd">        Args</span>
<span class="sd">        ----</span>
<span class="sd">            l : None | int</span>
<span class="sd">                layer index</span>
<span class="sd">            i : None | int</span>
<span class="sd">                neuron index</span>
<span class="sd">            out_score : None | torch.Tensor</span>
<span class="sd">                specify output scores</span>
<span class="sd">            plot : bool</span>
<span class="sd">                when plot = True, display the bar show</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">            torch.Tensor</span>
<span class="sd">                attribution scores</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_act</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Activations are not saved, cannot get attribution scores&quot;</span><span class="p">,</span>
                <span class="ne">RuntimeWarning</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">l</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">attribute</span><span class="p">()</span>
            <span class="n">out_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_scores</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>

        <span class="n">node_scores</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">subnode_scores</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">edge_scores</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">l_query</span> <span class="o">=</span> <span class="n">l</span>
        <span class="k">if</span> <span class="n">l</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">l_end</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">depth</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">l_end</span> <span class="o">=</span> <span class="n">l</span>

        <span class="c1"># back propagate from the queried layer</span>
        <span class="n">out_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="p">[</span><span class="n">l_end</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">out_score</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">node_score</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">out_dim</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">node_score</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">out_score</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">node_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node_score</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">l_end</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">subnode_score</span> <span class="o">=</span> <span class="n">node_score</span><span class="p">[:,</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="p">[</span><span class="n">l</span><span class="p">]]</span>

            <span class="n">subnode_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">subnode_score</span><span class="p">)</span>
            <span class="c1"># subnode to edge</span>
            <span class="n">edge_score</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span>
                <span class="s2">&quot;oi,ko,i-&gt;koi&quot;</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">edge_actscale</span><span class="p">[</span><span class="n">l</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span>
                <span class="n">subnode_score</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
                <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">subnode_actscale</span><span class="p">[</span><span class="n">l</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1e-4</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="n">edge_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">edge_score</span><span class="p">)</span>

            <span class="c1"># edge to node</span>
            <span class="n">node_score</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">edge_score</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">node_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node_score</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">node_scores_all</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="n">node_scores</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">edge_scores_all</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="n">edge_scores</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">subnode_scores_all</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="n">subnode_scores</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">node_scores</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_scores_all</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">edge_scores</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_scores_all</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">subnode_scores</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">subnode_scores_all</span><span class="p">]</span>

        <span class="c1"># return: (out_dim, in_dim)</span>
        <span class="k">if</span> <span class="n">l_query</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">i</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_scores_all</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># plot</span>
                <span class="k">if</span> <span class="n">plot</span><span class="p">:</span>
                    <span class="n">in_dim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span> <span class="o">*</span> <span class="n">in_dim</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
                    <span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span>
                        <span class="nb">range</span><span class="p">(</span><span class="n">in_dim</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_scores_all</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                    <span class="p">)</span>
                    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">in_dim</span><span class="p">))</span>

                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_scores_all</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">]</span></div>


<div class="viewcode-block" id="QKAN.node_attribute">
<a class="viewcode-back" href="../../api.html#qkan.QKAN.node_attribute">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">node_attribute</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get node attribution scores.</span>

<span class="sd">        Adapted from &quot;pykan&quot;.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">node_attribute_scores</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">node_attr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attribute</span><span class="p">(</span><span class="n">l</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">node_attribute_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node_attr</span><span class="p">)</span></div>


<div class="viewcode-block" id="QKAN.train_">
<a class="viewcode-back" href="../../api.html#qkan.QKAN.train_">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">train_</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">dataset</span><span class="p">,</span>
        <span class="n">optimizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">closure</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">scheduler</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
        <span class="n">log</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">loss_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">batch</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">lamb</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">lamb_l1</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">lamb_entropy</span><span class="o">=</span><span class="mf">2.0</span><span class="p">,</span>
        <span class="n">lamb_coef</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">lamb_coefdiff</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
        <span class="n">reg_metric</span><span class="o">=</span><span class="s2">&quot;edge_forward_dr_n&quot;</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train the model</span>

<span class="sd">        Args</span>
<span class="sd">        ----</span>
<span class="sd">            dataset : dict</span>
<span class="sd">                Dictionary containing train_input, train_label, test_input, test_label</span>
<span class="sd">            optimizer : torch.optim.Optimizer | None</span>
<span class="sd">                Optimizer to use, default: None</span>
<span class="sd">            closure : Callable | None</span>
<span class="sd">                Closure function for optimizer, default: None</span>
<span class="sd">            scheduler : torch.optim.lr_scheduler | None</span>
<span class="sd">                Scheduler to use, default: None</span>
<span class="sd">            steps : int</span>
<span class="sd">                Number of steps, default: 10</span>
<span class="sd">            log : int</span>
<span class="sd">                Logging frequency, default: 1</span>
<span class="sd">            loss_fn : torch.nn.Module | Callable |None</span>
<span class="sd">                Loss function to use, default: None</span>
<span class="sd">            batch : int</span>
<span class="sd">                batch size, if -1 then full., default: -1</span>
<span class="sd">            lamb : float</span>
<span class="sd">                L1 Regularization parameter. If 0, no regularization.</span>
<span class="sd">            lamb_l1 : float</span>
<span class="sd">                L1 Regularization parameter</span>
<span class="sd">            lamb_entropy : float</span>
<span class="sd">                Entropy Regularization parameter</span>
<span class="sd">            lamb_coef : float</span>
<span class="sd">                Coefficient Regularization parameter</span>
<span class="sd">            lamb_coefdiff : float</span>
<span class="sd">                Coefficient Smoothness Regularization parameter</span>
<span class="sd">            reg_metric : str</span>
<span class="sd">                Regularization metric.</span>
<span class="sd">                &#39;edge_forward_dr_n&#39;, &#39;edge_forward_dr_u&#39;, &#39;edge_forward_sum&#39;, &#39;edge_backward&#39;, &#39;node_backward&#39;</span>
<span class="sd">            verbose : bool</span>
<span class="sd">                Verbose mode, default: False</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">            dict</span>
<span class="sd">                Dictionary containing train_loss and test_loss</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">lamb</span> <span class="o">&gt;</span> <span class="mf">0.0</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_act</span><span class="p">:</span>
            <span class="n">lamb</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Regularization is not supported without saving activations&quot;</span><span class="p">,</span>
                <span class="ne">RuntimeWarning</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">steps</span><span class="p">),</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">loss_fn</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">loss_fn_eval</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">loss_fn_eval</span> <span class="o">=</span> <span class="n">loss_fn</span>

        <span class="k">if</span> <span class="n">optimizer</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">5e-4</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>

        <span class="n">results</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">results</span><span class="p">[</span><span class="s2">&quot;train_loss&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">results</span><span class="p">[</span><span class="s2">&quot;test_loss&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">results</span><span class="p">[</span><span class="s2">&quot;reg&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="n">batch</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span> <span class="ow">or</span> <span class="n">batch</span> <span class="o">&gt;</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train_input&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train_input&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">batch_size_test</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test_input&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch</span>
            <span class="n">batch_size_test</span> <span class="o">=</span> <span class="n">batch</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">_closure</span><span class="p">():</span>
            <span class="k">nonlocal</span> <span class="n">train_loss</span><span class="p">,</span> <span class="n">reg_</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train_input&quot;</span><span class="p">][</span><span class="n">train_id</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
            <span class="n">train_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train_label&quot;</span><span class="p">][</span><span class="n">train_id</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_act</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">reg_metric</span> <span class="o">==</span> <span class="s2">&quot;edge_backward&quot;</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">attribute</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">reg_metric</span> <span class="o">==</span> <span class="s2">&quot;node_backward&quot;</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">node_attribute</span><span class="p">()</span>
                <span class="n">reg_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_reg</span><span class="p">(</span>
                    <span class="n">reg_metric</span><span class="p">,</span> <span class="n">lamb_l1</span><span class="p">,</span> <span class="n">lamb_entropy</span><span class="p">,</span> <span class="n">lamb_coef</span><span class="p">,</span> <span class="n">lamb_coefdiff</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">reg_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">objective</span> <span class="o">=</span> <span class="n">train_loss</span> <span class="o">+</span> <span class="n">lamb</span> <span class="o">*</span> <span class="n">reg_</span>
            <span class="n">objective</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">objective</span>

        <span class="k">if</span> <span class="n">closure</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">LBFGS</span><span class="p">):</span>
            <span class="n">closure</span> <span class="o">=</span> <span class="n">_closure</span>

        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
            <span class="n">train_id</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
                <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train_input&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
            <span class="n">test_id</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
                <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test_input&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">batch_size_test</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">LBFGS</span><span class="p">):</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train_input&quot;</span><span class="p">][</span><span class="n">train_id</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
                <span class="n">train_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span>
                    <span class="n">pred</span><span class="p">,</span> <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;train_label&quot;</span><span class="p">][</span><span class="n">train_id</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_act</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">reg_metric</span> <span class="o">==</span> <span class="s2">&quot;edge_backward&quot;</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">attribute</span><span class="p">()</span>
                    <span class="k">if</span> <span class="n">reg_metric</span> <span class="o">==</span> <span class="s2">&quot;node_backward&quot;</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">node_attribute</span><span class="p">()</span>
                    <span class="n">reg_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_reg</span><span class="p">(</span>
                        <span class="n">reg_metric</span><span class="p">,</span> <span class="n">lamb_l1</span><span class="p">,</span> <span class="n">lamb_entropy</span><span class="p">,</span> <span class="n">lamb_coef</span><span class="p">,</span> <span class="n">lamb_coefdiff</span>
                    <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">reg_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">train_loss</span> <span class="o">+</span> <span class="n">lamb</span> <span class="o">*</span> <span class="n">reg_</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">closure</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
            <span class="n">test_loss</span> <span class="o">=</span> <span class="n">loss_fn_eval</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test_input&quot;</span><span class="p">][</span><span class="n">test_id</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)),</span>
                <span class="n">dataset</span><span class="p">[</span><span class="s2">&quot;test_label&quot;</span><span class="p">][</span><span class="n">test_id</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">scheduler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">test_loss</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">_</span> <span class="o">%</span> <span class="n">log</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">pbar</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span>
                    <span class="p">{</span>
                        <span class="s2">&quot;train loss&quot;</span><span class="p">:</span> <span class="n">train_loss</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
                        <span class="s2">&quot;test loss&quot;</span><span class="p">:</span> <span class="n">test_loss</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
                    <span class="p">}</span>
                <span class="p">)</span>

            <span class="n">results</span><span class="p">[</span><span class="s2">&quot;train_loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            <span class="n">results</span><span class="p">[</span><span class="s2">&quot;test_loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_loss</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            <span class="n">results</span><span class="p">[</span><span class="s2">&quot;reg&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">reg_</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

        <span class="k">return</span> <span class="n">results</span></div>


<div class="viewcode-block" id="QKAN.plot">
<a class="viewcode-back" href="../../api.html#qkan.QKAN.plot">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">plot</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">x0</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">sampling</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
        <span class="n">from_acts</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">scale</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
        <span class="n">beta</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;forward_n&quot;</span><span class="p">,</span>
        <span class="n">mask</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">in_vars</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">out_vars</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">title</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Plot the model.</span>

<span class="sd">        Adapted from &quot;pykan&quot;.</span>

<span class="sd">        Arguments</span>
<span class="sd">        ---------</span>
<span class="sd">            x0 : torch.Tensor | None</span>
<span class="sd">                Input tensor to plot, if None, plot from saved activations</span>
<span class="sd">            sampling : int</span>
<span class="sd">                Sampling frequency</span>
<span class="sd">            from_acts : bool</span>
<span class="sd">                Plot from saved activations</span>
<span class="sd">            scale : float</span>
<span class="sd">                Scale of the plot</span>
<span class="sd">            beta : float</span>
<span class="sd">                Beta value</span>
<span class="sd">            metric : str</span>
<span class="sd">                Metric to use. &#39;forward_n&#39;, &#39;forward_u&#39;, &#39;backward&#39;</span>
<span class="sd">            in_vars : list[int] | None</span>
<span class="sd">                Input variables to plot</span>
<span class="sd">            out_vars : list[int] | None</span>
<span class="sd">                Output variables to plot</span>
<span class="sd">            title : str | None</span>
<span class="sd">                Title of the plot</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_map</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Not supported for map layer&quot;</span><span class="p">,</span> <span class="ne">RuntimeWarning</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_batchnorm</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;Not supported for batchnorm layer&quot;</span><span class="p">,</span> <span class="ne">RuntimeWarning</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">x0</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">from_acts</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;x0 is not provided, try plot from saved activations.&quot;</span><span class="p">,</span> <span class="ne">RuntimeWarning</span>
            <span class="p">)</span>
            <span class="n">from_acts</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="n">from_acts</span> <span class="ow">and</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">acts</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Activations are not saved, cannot plot from activations&quot;</span><span class="p">,</span>
                <span class="ne">RuntimeWarning</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">mask</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;mask&quot;</span><span class="p">):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Make sure to run model.prune_node() first to compute mask. Continue without mask.&quot;</span><span class="p">,</span>
                <span class="ne">RuntimeWarning</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="s2">&quot;./figures&quot;</span><span class="p">):</span>
            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="s2">&quot;./figures&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">metric</span> <span class="o">==</span> <span class="s2">&quot;backward&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">attribute</span><span class="p">()</span>

        <span class="n">save_act</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_act</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_act</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">qkan_layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>
            <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">qkan_layer</span><span class="p">,</span> <span class="n">QKANLayer</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">idx</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">x0</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">ymin</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">ynew</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>  <span class="c1"># noqa: F821</span>
                <span class="n">ymax</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">ynew</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">values</span>  <span class="c1"># noqa: F821</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span>
                            <span class="n">ymin</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                            <span class="n">ymax</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                            <span class="n">steps</span><span class="o">=</span><span class="n">sampling</span><span class="p">,</span>
                            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
                        <span class="p">)</span>
                        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">qkan_layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span>
                    <span class="p">]</span>
                <span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># x.shape = (sampling, in_dim)</span>
            <span class="k">if</span> <span class="n">from_acts</span><span class="p">:</span>
                <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">acts</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>

            <span class="n">y</span> <span class="o">=</span> <span class="n">qkan_layer</span><span class="o">.</span><span class="n">forward_no_sum</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span>
                <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span>
            <span class="p">)</span>  <span class="c1"># y.shape = (sampling, in_dim, out_dim)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="p">[</span><span class="n">idx</span><span class="p">]):</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]):</span>
                    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
                    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([])</span>
                    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>
                    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">patch</span><span class="o">.</span><span class="n">set_edgecolor</span><span class="p">(</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
                    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">patch</span><span class="o">.</span><span class="n">set_linewidth</span><span class="p">(</span><span class="mf">1.5</span><span class="p">)</span>
                    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
                        <span class="n">x</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
                        <span class="n">y</span><span class="p">[:,</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span>
                        <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span>
                        <span class="n">s</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">spines</span><span class="p">[:]</span><span class="o">.</span><span class="n">set_color</span><span class="p">(</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
                    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;./figures/dr_</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">j</span><span class="si">}</span><span class="s2">.png&quot;</span><span class="p">,</span> <span class="n">bbox_inches</span><span class="o">=</span><span class="s2">&quot;tight&quot;</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">400</span>
                    <span class="p">)</span>
                    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">ynew</span> <span class="o">=</span> <span class="n">qkan_layer</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># noqa: F841</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">score2alpha</span><span class="p">(</span><span class="n">score</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">beta</span> <span class="o">*</span> <span class="n">score</span><span class="p">)</span>

        <span class="n">alpha</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">save_act</span> <span class="ow">and</span> <span class="n">metric</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">metric</span> <span class="o">==</span> <span class="s2">&quot;forward_n&quot;</span><span class="p">:</span>
                    <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">acts_scale</span>
                <span class="k">elif</span> <span class="n">metric</span> <span class="o">==</span> <span class="s2">&quot;forward_u&quot;</span><span class="p">:</span>
                    <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_actscale</span>
                <span class="k">elif</span> <span class="n">metric</span> <span class="o">==</span> <span class="s2">&quot;backward&quot;</span><span class="p">:</span>
                    <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">edge_scores</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;metric = &#39;</span><span class="si">{</span><span class="n">metric</span><span class="si">}</span><span class="s2">&#39; cannot be recognized&quot;</span><span class="p">)</span>

                <span class="n">alpha</span> <span class="o">=</span> <span class="p">[</span><span class="n">score2alpha</span><span class="p">(</span><span class="n">score</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span> <span class="k">for</span> <span class="n">score</span> <span class="ow">in</span> <span class="n">scores</span><span class="p">]</span>
        <span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;metric = &#39;</span><span class="si">{</span><span class="n">metric</span><span class="si">}</span><span class="s2">&#39; cannot be recognized&quot;</span><span class="p">,</span> <span class="ne">RuntimeWarning</span><span class="p">)</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">alpha</span><span class="p">:</span>
                <span class="n">alpha</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span>
                <span class="p">]</span>

        <span class="c1"># draw skeleton</span>
        <span class="n">width</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="p">)</span>
        <span class="n">A</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">y0</span> <span class="o">=</span> <span class="mf">0.4</span>

        <span class="n">neuron_depth</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">width</span><span class="p">)</span>
        <span class="n">min_spacing</span> <span class="o">=</span> <span class="n">A</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">width</span><span class="p">),</span> <span class="mi">5</span><span class="p">)</span>

        <span class="c1"># max_neuron = np.max(width)</span>
        <span class="n">max_num_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">width</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">width</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
        <span class="n">y1</span> <span class="o">=</span> <span class="mf">0.4</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">max_num_weights</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span>
            <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span> <span class="o">*</span> <span class="n">scale</span><span class="p">,</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">scale</span> <span class="o">*</span> <span class="p">(</span><span class="n">neuron_depth</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">y0</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="c1"># plot scatters and lines</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">neuron_depth</span><span class="p">):</span>
            <span class="n">n</span> <span class="o">=</span> <span class="n">width</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>
            <span class="c1"># spacing = A / n</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
                    <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n</span><span class="p">)</span> <span class="o">+</span> <span class="n">i</span> <span class="o">/</span> <span class="n">n</span><span class="p">,</span>
                    <span class="n">l</span> <span class="o">*</span> <span class="n">y0</span><span class="p">,</span>
                    <span class="n">s</span><span class="o">=</span><span class="n">min_spacing</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="mi">10000</span> <span class="o">*</span> <span class="n">scale</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span>
                    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="k">if</span> <span class="n">l</span> <span class="o">&lt;</span> <span class="n">neuron_depth</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="c1"># plot connections</span>
                    <span class="n">n_next</span> <span class="o">=</span> <span class="n">width</span><span class="p">[</span><span class="n">l</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
                    <span class="n">N</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="n">n_next</span>
                    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_next</span><span class="p">):</span>
                        <span class="n">id_</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="n">n_next</span> <span class="o">+</span> <span class="n">j</span>
                        <span class="k">if</span> <span class="n">mask</span><span class="p">:</span>
                            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
                                <span class="p">[</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n</span><span class="p">)</span> <span class="o">+</span> <span class="n">i</span> <span class="o">/</span> <span class="n">n</span><span class="p">,</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">N</span><span class="p">)</span> <span class="o">+</span> <span class="n">id_</span> <span class="o">/</span> <span class="n">N</span><span class="p">],</span>
                                <span class="p">[</span><span class="n">l</span> <span class="o">*</span> <span class="n">y0</span><span class="p">,</span> <span class="p">(</span><span class="n">l</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">y0</span> <span class="o">-</span> <span class="n">y1</span><span class="p">],</span>
                                <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span>
                                <span class="n">lw</span><span class="o">=</span><span class="mi">2</span> <span class="o">*</span> <span class="n">scale</span><span class="p">,</span>
                                <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">[</span><span class="n">l</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
                                <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">[</span><span class="n">l</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                                <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">[</span><span class="n">l</span> <span class="o">+</span> <span class="mi">1</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                            <span class="p">)</span>
                            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
                                <span class="p">[</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">N</span><span class="p">)</span> <span class="o">+</span> <span class="n">id_</span> <span class="o">/</span> <span class="n">N</span><span class="p">,</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n_next</span><span class="p">)</span> <span class="o">+</span> <span class="n">j</span> <span class="o">/</span> <span class="n">n_next</span><span class="p">],</span>
                                <span class="p">[(</span><span class="n">l</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">y0</span> <span class="o">+</span> <span class="n">y1</span><span class="p">,</span> <span class="p">(</span><span class="n">l</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">y0</span><span class="p">],</span>
                                <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span>
                                <span class="n">lw</span><span class="o">=</span><span class="mi">2</span> <span class="o">*</span> <span class="n">scale</span><span class="p">,</span>
                                <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">[</span><span class="n">l</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
                                <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">[</span><span class="n">l</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                                <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">[</span><span class="n">l</span> <span class="o">+</span> <span class="mi">1</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                            <span class="p">)</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
                                <span class="p">[</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n</span><span class="p">)</span> <span class="o">+</span> <span class="n">i</span> <span class="o">/</span> <span class="n">n</span><span class="p">,</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">N</span><span class="p">)</span> <span class="o">+</span> <span class="n">id_</span> <span class="o">/</span> <span class="n">N</span><span class="p">],</span>
                                <span class="p">[</span><span class="n">l</span> <span class="o">*</span> <span class="n">y0</span><span class="p">,</span> <span class="p">(</span><span class="n">l</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">y0</span> <span class="o">-</span> <span class="n">y1</span><span class="p">],</span>
                                <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span>
                                <span class="n">lw</span><span class="o">=</span><span class="mi">2</span> <span class="o">*</span> <span class="n">scale</span><span class="p">,</span>
                                <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">[</span><span class="n">l</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">i</span><span class="p">],</span>
                            <span class="p">)</span>
                            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
                                <span class="p">[</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">N</span><span class="p">)</span> <span class="o">+</span> <span class="n">id_</span> <span class="o">/</span> <span class="n">N</span><span class="p">,</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n_next</span><span class="p">)</span> <span class="o">+</span> <span class="n">j</span> <span class="o">/</span> <span class="n">n_next</span><span class="p">],</span>
                                <span class="p">[(</span><span class="n">l</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">y0</span> <span class="o">+</span> <span class="n">y1</span><span class="p">,</span> <span class="p">(</span><span class="n">l</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">y0</span><span class="p">],</span>
                                <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span>
                                <span class="n">lw</span><span class="o">=</span><span class="mi">2</span> <span class="o">*</span> <span class="n">scale</span><span class="p">,</span>
                                <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">[</span><span class="n">l</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">i</span><span class="p">],</span>
                            <span class="p">)</span>

            <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.1</span> <span class="o">*</span> <span class="n">y0</span><span class="p">,</span> <span class="p">(</span><span class="n">neuron_depth</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">)</span> <span class="o">*</span> <span class="n">y0</span><span class="p">)</span>

        <span class="c1"># -- Transformation functions</span>
        <span class="n">DC_to_FC</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">transData</span><span class="o">.</span><span class="n">transform</span>
        <span class="n">FC_to_NFC</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">transFigure</span><span class="o">.</span><span class="n">inverted</span><span class="p">()</span><span class="o">.</span><span class="n">transform</span>
        <span class="c1"># -- Take data coordinates and transform them to normalized figure coordinates</span>
        <span class="n">DC_to_NFC</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">FC_to_NFC</span><span class="p">(</span><span class="n">DC_to_FC</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>

        <span class="c1"># plot splines</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">neuron_depth</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">n</span> <span class="o">=</span> <span class="n">width</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
                <span class="n">n_next</span> <span class="o">=</span> <span class="n">width</span><span class="p">[</span><span class="n">l</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
                <span class="n">N</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="n">n_next</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_next</span><span class="p">):</span>
                    <span class="n">id_</span> <span class="o">=</span> <span class="n">i</span> <span class="o">*</span> <span class="n">n_next</span> <span class="o">+</span> <span class="n">j</span>
                    <span class="n">im</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;./figures/dr_</span><span class="si">{</span><span class="n">l</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">j</span><span class="si">}</span><span class="s2">.png&quot;</span><span class="p">)</span>
                    <span class="n">left</span> <span class="o">=</span> <span class="n">DC_to_NFC</span><span class="p">([</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">N</span><span class="p">)</span> <span class="o">+</span> <span class="n">id_</span> <span class="o">/</span> <span class="n">N</span> <span class="o">-</span> <span class="n">y1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="n">right</span> <span class="o">=</span> <span class="n">DC_to_NFC</span><span class="p">([</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">N</span><span class="p">)</span> <span class="o">+</span> <span class="n">id_</span> <span class="o">/</span> <span class="n">N</span> <span class="o">+</span> <span class="n">y1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="n">bottom</span> <span class="o">=</span> <span class="n">DC_to_NFC</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="n">l</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">y0</span> <span class="o">-</span> <span class="n">y1</span><span class="p">])[</span><span class="mi">1</span><span class="p">]</span>
                    <span class="n">up</span> <span class="o">=</span> <span class="n">DC_to_NFC</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="n">l</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">y0</span> <span class="o">+</span> <span class="n">y1</span><span class="p">])[</span><span class="mi">1</span><span class="p">]</span>
                    <span class="n">newax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_axes</span><span class="p">([</span><span class="n">left</span><span class="p">,</span> <span class="n">bottom</span><span class="p">,</span> <span class="n">right</span> <span class="o">-</span> <span class="n">left</span><span class="p">,</span> <span class="n">up</span> <span class="o">-</span> <span class="n">bottom</span><span class="p">])</span>
                    <span class="k">if</span> <span class="n">mask</span><span class="p">:</span>
                        <span class="n">newax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span>
                            <span class="n">im</span><span class="p">,</span>
                            <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">[</span><span class="n">l</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
                            <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">[</span><span class="n">l</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                            <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask</span><span class="p">[</span><span class="n">l</span> <span class="o">+</span> <span class="mi">1</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
                        <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">newax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">im</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">[</span><span class="n">l</span><span class="p">][</span><span class="n">j</span><span class="p">][</span><span class="n">i</span><span class="p">])</span>
                    <span class="n">newax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">in_vars</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">get_axes</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span>
                    <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span><span class="p">))</span> <span class="o">+</span> <span class="n">i</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span><span class="p">),</span>
                    <span class="o">-</span><span class="mf">0.1</span><span class="p">,</span>
                    <span class="n">in_vars</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                    <span class="n">fontsize</span><span class="o">=</span><span class="mi">40</span> <span class="o">*</span> <span class="n">scale</span><span class="p">,</span>
                    <span class="n">horizontalalignment</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span>
                    <span class="n">verticalalignment</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="n">out_vars</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">get_axes</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span>
                    <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span><span class="p">))</span> <span class="o">+</span> <span class="n">i</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span><span class="p">),</span>
                    <span class="n">y0</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.1</span><span class="p">,</span>
                    <span class="n">out_vars</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                    <span class="n">fontsize</span><span class="o">=</span><span class="mi">40</span> <span class="o">*</span> <span class="n">scale</span><span class="p">,</span>
                    <span class="n">horizontalalignment</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span>
                    <span class="n">verticalalignment</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="n">title</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">get_axes</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span>
                <span class="mf">0.5</span><span class="p">,</span>
                <span class="n">y0</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.2</span><span class="p">,</span>
                <span class="n">title</span><span class="p">,</span>
                <span class="n">fontsize</span><span class="o">=</span><span class="mi">40</span> <span class="o">*</span> <span class="n">scale</span><span class="p">,</span>
                <span class="n">horizontalalignment</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span>
                <span class="n">verticalalignment</span><span class="o">=</span><span class="s2">&quot;center&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_act</span> <span class="o">=</span> <span class="n">save_act</span></div>


<div class="viewcode-block" id="QKAN.prune_node">
<a class="viewcode-back" href="../../api.html#qkan.QKAN.prune_node">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">prune_node</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-2</span><span class="p">,</span>
        <span class="n">mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span><span class="p">,</span>
        <span class="n">active_neurons_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Pruning nodes.</span>

<span class="sd">        Adapted from &quot;pykan&quot;.</span>

<span class="sd">        Args</span>
<span class="sd">        ----</span>
<span class="sd">            threshold : float</span>
<span class="sd">                if the attribution score of a neuron is below the threshold, it is considered dead and will be removed</span>
<span class="sd">            mode : str</span>
<span class="sd">                &quot;auto&quot; or &quot;manual&quot;. with &quot;auto&quot;, nodes are automatically pruned using threshold.</span>
<span class="sd">                With &quot;manual&quot;, active_neurons_id should be passed in.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">            QKAN</span>
<span class="sd">                pruned network</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;acts&quot;</span><span class="p">):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;No activations, cannot prune nodes&quot;</span><span class="p">,</span> <span class="ne">RuntimeWarning</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;manual&quot;</span> <span class="ow">and</span> <span class="n">active_neurons_id</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;active_neurons_id is not provided. Continue with auto mode.&quot;</span><span class="p">,</span>
                <span class="ne">RuntimeWarning</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">mode</span> <span class="o">=</span> <span class="s2">&quot;auto&quot;</span>

        <span class="n">mask</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="p">)</span>
        <span class="p">]</span>
        <span class="n">active_neurons</span> <span class="o">=</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="p">[</span><span class="mi">0</span><span class="p">]))]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">acts_scale</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;auto&quot;</span><span class="p">:</span>
                <span class="n">in_important</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">acts_scale</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">threshold</span>
                <span class="n">out_important</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">acts_scale</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">threshold</span>
                <span class="n">overall_important</span> <span class="o">=</span> <span class="n">in_important</span> <span class="o">*</span> <span class="n">out_important</span>
            <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;manual&quot;</span><span class="p">:</span>
                <span class="k">assert</span> <span class="n">active_neurons_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                <span class="n">overall_important</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
                <span class="n">overall_important</span><span class="p">[</span><span class="n">active_neurons_id</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">mask</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">overall_important</span><span class="o">.</span><span class="n">float</span><span class="p">())</span>
            <span class="n">active_neurons</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">overall_important</span> <span class="o">==</span> <span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>  <span class="c1"># noqa: E712</span>
            <span class="p">)</span>
        <span class="n">active_neurons</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])))</span>
        <span class="n">mask</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
            <span class="p">)</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span>  <span class="c1"># for plot</span>

        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">acts_scale</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="p">[</span><span class="n">l</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]):</span>
                <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">active_neurons</span><span class="p">[</span><span class="n">l</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">remove_node</span><span class="p">(</span><span class="n">l</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>

        <span class="n">model2</span> <span class="o">=</span> <span class="n">QKAN</span><span class="p">(</span>
            <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="p">),</span>
            <span class="n">reps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reps</span><span class="p">,</span>
            <span class="n">is_map</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">is_map</span><span class="p">,</span>
            <span class="n">is_batchnorm</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">is_batchnorm</span><span class="p">,</span>
            <span class="n">hidden</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="n">solver</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="p">,</span>
            <span class="n">qml_device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">qml_device</span><span class="p">,</span>
            <span class="n">ansatz</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ansatz</span><span class="p">,</span>
            <span class="n">norm_out</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">norm_out</span><span class="p">,</span>
            <span class="n">preact_trainable</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">preact_trainable</span><span class="p">,</span>
            <span class="n">postact_weight_trainable</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">postact_weight_trainable</span><span class="p">,</span>
            <span class="n">postact_bias_trainable</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">postact_bias_trainable</span><span class="p">,</span>
            <span class="n">base_activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">base_activation</span><span class="p">,</span>
            <span class="n">ba_trainable</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ba_trainable</span><span class="p">,</span>
            <span class="n">save_act</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">save_act</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">model2</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">model2</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">QKANLayer</span><span class="p">):</span>
                <span class="k">continue</span>
            <span class="n">model2</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">get_subset</span><span class="p">(</span>
                <span class="n">active_neurons</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">active_neurons</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
            <span class="p">)</span>
            <span class="n">model2</span><span class="o">.</span><span class="n">width</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">active_neurons</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="n">model2</span><span class="o">.</span><span class="n">cache_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache_data</span>

        <span class="k">return</span> <span class="n">model2</span></div>


<div class="viewcode-block" id="QKAN.prune_edge">
<a class="viewcode-back" href="../../api.html#qkan.QKAN.prune_edge">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">prune_edge</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">3e-2</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Pruning edges.</span>

<span class="sd">        Adapted from &quot;pykan&quot;.</span>

<span class="sd">        Args:</span>
<span class="sd">            threshold: float</span>
<span class="sd">                if the attribution score of an edge is below the threshold, it is considered dead and will be set to zero.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;acts&quot;</span><span class="p">):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;No activations, cannot prune edges&quot;</span><span class="p">,</span> <span class="ne">RuntimeWarning</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">old_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">mask</span><span class="o">.</span><span class="n">data</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">mask</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="p">(</span>
                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">edge_scores</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">)</span> <span class="o">*</span> <span class="n">old_mask</span>
            <span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span></div>


<div class="viewcode-block" id="QKAN.prune">
<a class="viewcode-back" href="../../api.html#qkan.QKAN.prune">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">prune</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_th</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-2</span><span class="p">,</span> <span class="n">edge_th</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">3e-2</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Prune (both nodes and edges).</span>

<span class="sd">        Adapted from &quot;pykan&quot;.</span>

<span class="sd">        Args</span>
<span class="sd">        ----</span>
<span class="sd">            node_th : float</span>
<span class="sd">                if the attribution score of a node is below node_th, it is considered dead and will be set to zero.</span>
<span class="sd">            edge_th : float</span>
<span class="sd">                if the attribution score of an edge is below node_th, it is considered dead and will be set to zero.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">            QKAN</span>
<span class="sd">                pruned network</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;acts&quot;</span><span class="p">):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s2">&quot;No activations, cannot prune.&quot;</span><span class="p">,</span> <span class="ne">RuntimeWarning</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span>

        <span class="bp">self</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prune_node</span><span class="p">(</span><span class="n">node_th</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cache_data</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">attribute</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prune_edge</span><span class="p">(</span><span class="n">edge_th</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="QKAN.prune_input">
<a class="viewcode-back" href="../../api.html#qkan.QKAN.prune_input">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">prune_input</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-2</span><span class="p">,</span> <span class="n">active_inputs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">list</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Prune inputs.</span>

<span class="sd">        Adapted from &quot;pykan&quot;.</span>

<span class="sd">        Args</span>
<span class="sd">        ----</span>
<span class="sd">            threshold : float</span>
<span class="sd">                if the attribution score of the input feature is below threshold, it is considered irrelevant.</span>
<span class="sd">            active_inputs : list | None</span>
<span class="sd">                if a list is passed, the manual mode will disregard attribution score and prune as instructed.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">            QKAN</span>
<span class="sd">                pruned network</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">active_inputs</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">attribute</span><span class="p">()</span>
            <span class="n">input_score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">input_mask</span> <span class="o">=</span> <span class="n">input_score</span> <span class="o">&gt;</span> <span class="n">threshold</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;keep:&quot;</span><span class="p">,</span> <span class="n">input_mask</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
            <span class="n">input_id</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">input_mask</span> <span class="o">==</span> <span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># noqa: E712</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">input_id</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">active_inputs</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="n">model2</span> <span class="o">=</span> <span class="n">QKAN</span><span class="p">(</span>
            <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="p">),</span>
            <span class="n">reps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">reps</span><span class="p">,</span>
            <span class="n">is_map</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">is_map</span><span class="p">,</span>
            <span class="n">is_batchnorm</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">is_batchnorm</span><span class="p">,</span>
            <span class="n">hidden</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="n">solver</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">solver</span><span class="p">,</span>
            <span class="n">qml_device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">qml_device</span><span class="p">,</span>
            <span class="n">ansatz</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ansatz</span><span class="p">,</span>
            <span class="n">norm_out</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">norm_out</span><span class="p">,</span>
            <span class="n">preact_trainable</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">preact_trainable</span><span class="p">,</span>
            <span class="n">postact_weight_trainable</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">postact_weight_trainable</span><span class="p">,</span>
            <span class="n">postact_bias_trainable</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">postact_bias_trainable</span><span class="p">,</span>
            <span class="n">base_activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">base_activation</span><span class="p">,</span>
            <span class="n">ba_trainable</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">ba_trainable</span><span class="p">,</span>
            <span class="n">save_act</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">save_act</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">model2</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>

        <span class="n">model2</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">model2</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_subset</span><span class="p">(</span>
            <span class="n">input_id</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">width</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="p">)</span>

        <span class="n">model2</span><span class="o">.</span><span class="n">cache_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cache_data</span>

        <span class="n">model2</span><span class="o">.</span><span class="n">width</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_id</span><span class="p">)</span>
        <span class="n">model2</span><span class="o">.</span><span class="n">input_id</span> <span class="o">=</span> <span class="n">input_id</span>

        <span class="k">return</span> <span class="n">model2</span></div>


<div class="viewcode-block" id="QKAN.remove_edge">
<a class="viewcode-back" href="../../api.html#qkan.QKAN.remove_edge">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">remove_edge</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_idx</span><span class="p">,</span> <span class="n">in_idx</span><span class="p">,</span> <span class="n">out_idx</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Remove activtion phi(layer_idx, in_idx, out_idx) (set its mask to zero)</span>

<span class="sd">        Args</span>
<span class="sd">        ----</span>
<span class="sd">            layer_idx : int</span>
<span class="sd">                Layer index</span>
<span class="sd">            in_idx : int</span>
<span class="sd">                Input node index</span>
<span class="sd">            out_idx : int</span>
<span class="sd">                Output node index</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">layer_idx</span><span class="p">],</span> <span class="n">QKAN</span><span class="p">):</span>
            <span class="k">return</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">layer_idx</span><span class="p">]</span><span class="o">.</span><span class="n">mask</span><span class="p">[</span><span class="n">out_idx</span><span class="p">,</span> <span class="n">in_idx</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span></div>


<div class="viewcode-block" id="QKAN.remove_node">
<a class="viewcode-back" href="../../api.html#qkan.QKAN.remove_node">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">remove_node</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer_idx</span><span class="p">,</span> <span class="n">in_idx</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        remove neuron (layer_idx, in_idx) (set the masks of all incoming and outgoing activation functions to zero)</span>

<span class="sd">        Args</span>
<span class="sd">        ----</span>
<span class="sd">            layer_idx : int</span>
<span class="sd">                Layer index</span>
<span class="sd">            in_idx : int</span>
<span class="sd">                Input node index</span>
<span class="sd">            mode : str</span>
<span class="sd">                Mode to remove. &quot;all&quot; or &quot;up&quot; or &quot;down&quot;, default: &quot;all&quot;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;down&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">layer_idx</span> <span class="o">-</span> <span class="mi">1</span><span class="p">],</span> <span class="n">QKAN</span><span class="p">):</span>
                <span class="k">return</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">layer_idx</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">mask</span><span class="p">[</span><span class="n">in_idx</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;up&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">layer_idx</span><span class="p">],</span> <span class="n">QKAN</span><span class="p">):</span>
                <span class="k">return</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">layer_idx</span><span class="p">]</span><span class="o">.</span><span class="n">mask</span><span class="p">[:,</span> <span class="n">in_idx</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">remove_node</span><span class="p">(</span><span class="n">layer_idx</span><span class="p">,</span> <span class="n">in_idx</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;up&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">remove_node</span><span class="p">(</span><span class="n">layer_idx</span><span class="p">,</span> <span class="n">in_idx</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;down&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="QKAN.clear_ckpts">
<a class="viewcode-back" href="../../api.html#qkan.QKAN.clear_ckpts">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">clear_ckpts</span><span class="p">(</span><span class="n">folder</span><span class="o">=</span><span class="s2">&quot;./model_ckpt&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Clear all checkpoints.</span>

<span class="sd">        Args</span>
<span class="sd">        ----</span>
<span class="sd">            folder : str</span>
<span class="sd">                Folder containing checkpoints, default: &quot;./model_ckpt&quot;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">folder</span><span class="p">):</span>
            <span class="n">files</span> <span class="o">=</span> <span class="n">glob</span><span class="p">(</span><span class="n">folder</span> <span class="o">+</span> <span class="s2">&quot;/*&quot;</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">files</span><span class="p">:</span>
                <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">folder</span><span class="p">)</span></div>


<div class="viewcode-block" id="QKAN.save_ckpt">
<a class="viewcode-back" href="../../api.html#qkan.QKAN.save_ckpt">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">save_ckpt</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">folder</span><span class="o">=</span><span class="s2">&quot;./model_ckpt&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Save the current model as checkpoint.</span>

<span class="sd">        Args</span>
<span class="sd">        ----</span>
<span class="sd">            name : str</span>
<span class="sd">                Name of the checkpoint</span>
<span class="sd">            folder : str</span>
<span class="sd">                Folder to save the checkpoint, default: &quot;./model_ckpt&quot;</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">folder</span><span class="p">):</span>
            <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">folder</span><span class="p">)</span>

        <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="n">folder</span> <span class="o">+</span> <span class="s2">&quot;/&quot;</span> <span class="o">+</span> <span class="n">name</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;save this model to&quot;</span><span class="p">,</span> <span class="n">folder</span> <span class="o">+</span> <span class="s2">&quot;/&quot;</span> <span class="o">+</span> <span class="n">name</span><span class="p">)</span></div>


<div class="viewcode-block" id="QKAN.load_ckpt">
<a class="viewcode-back" href="../../api.html#qkan.QKAN.load_ckpt">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">load_ckpt</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">folder</span><span class="o">=</span><span class="s2">&quot;./model_ckpt&quot;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load a checkpoint to the current model.</span>

<span class="sd">        Args</span>
<span class="sd">        ----</span>
<span class="sd">            name : str</span>
<span class="sd">                Name of the checkpoint</span>
<span class="sd">            folder : str</span>
<span class="sd">                Folder containing the checkpoint, default: &quot;./model_ckpt&quot;</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">folder</span> <span class="o">+</span> <span class="s2">&quot;/&quot;</span> <span class="o">+</span> <span class="n">name</span><span class="p">))</span></div>
</div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Jiun-Cheng Jiang.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>